{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import glob \n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    # CuDNN 결정론적 옵션 설정\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# 원하는 시드 값 설정\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # 디바이스 설정\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_list = os.listdir('./real_test')\n",
    "print(len(people_list))\n",
    "print(people_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_image_paths = glob.glob(os.path.join('real_test','pair*','L.jpg'))\n",
    "right_image_paths = glob.glob(os.path.join('real_test','pair*','R.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(left_image_paths))\n",
    "print(left_image_paths[:10])\n",
    "print(len(right_image_paths))\n",
    "print(right_image_paths[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(image_size = 112, keep_all=False).to(device) # keep_all=True면 여러 얼굴 반환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from facenet_pytorch import MTCNN, extract_face\n",
    "mtcnn = MTCNN(keep_all=False,device=device) # keep_all=True면 여러 얼굴 반환\n",
    "\n",
    "detect_count = 0 \n",
    "not_detect_count = 0\n",
    "\n",
    "for image_path in tqdm(left_image_paths+right_image_paths):\n",
    "    folder,pair,file_name = image_path.split('/')\n",
    "    new_image_path = os.path.join('crop_real_test',pair,file_name)\n",
    "    \n",
    "    if not os.path.exists(os.path.join('crop_real_test',pair)):\n",
    "        os.makedirs(os.path.join('crop_real_test',pair))\n",
    "        \n",
    "    img = Image.open(image_path)\n",
    "    face, _ = mtcnn.detect(img)\n",
    "\n",
    "    if face is not None:\n",
    "        x1, y1, x2, y2 = [int(coord) for coord in face[0]]\n",
    "        cropped_face = img.crop((x1-10, y1-10, x2+10, y2))\n",
    "        save_path = new_image_path\n",
    "        cropped_face.save(save_path)\n",
    "        detect_count+=1\n",
    "    else:\n",
    "        h = 230\n",
    "        w = 346\n",
    "        x1 = w//2-h//2\n",
    "        x2 = w//2+h//2\n",
    "        y1 = 0\n",
    "        y2 = h\n",
    "        cropped_face = img.crop((x1, y1, x2, y2))\n",
    "        save_path = new_image_path\n",
    "        cropped_face.save(save_path)\n",
    "        not_detect_count+=1\n",
    "        \n",
    "print(f'detect : {detect_count}, not_detect : {not_detect_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_left_image_paths = glob.glob(os.path.join('crop_real_test','pair*','L.jpg'))\n",
    "crop_right_image_paths = glob.glob(os.path.join('crop_real_test','pair*','R.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = './crop_real_test'\n",
    "\n",
    "fig,axes = plt.subplots(5,2,figsize=(6,12))\n",
    "\n",
    "for i,idx in enumerate(range(0,5)):\n",
    "    left_image = os.path.join(image_path,f'pair{idx}',f'L.jpg')\n",
    "    right_image = os.path.join(image_path,f'pair{idx}',f'R.jpg')\n",
    "    \n",
    "    left_image_bgr = cv2.imread(left_image)\n",
    "    left_image_rgb = cv2.cvtColor(left_image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    right_image_bgr = cv2.imread(right_image)\n",
    "    right_image_rgb = cv2.cvtColor(right_image_bgr, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    ax = axes[i, 0]\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f\"Label: {idx}_left\")\n",
    "    ax.imshow(left_image_rgb)\n",
    "    \n",
    "    ax = axes[i, 1]\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f\"Label: {idx}_right\")\n",
    "    ax.imshow(right_image_rgb)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
